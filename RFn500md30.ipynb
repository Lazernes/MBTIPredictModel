{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6J1uoA0aV0e",
        "outputId": "a68c4f6c-7ef8-43d9-8257-ed2f79dc175e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/zeyadkhalid/mbti-personality-types-500-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 123M/123M [00:01<00:00, 78.5MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/zeyadkhalid/mbti-personality-types-500-dataset/versions/1\n",
            "I_E Balance:\n",
            " I_E\n",
            "0    25390\n",
            "1    25390\n",
            "Name: count, dtype: int64\n",
            "N_S Balance:\n",
            " N_S\n",
            "0    9201\n",
            "1    9201\n",
            "Name: count, dtype: int64\n",
            "T_F Balance:\n",
            " T_F\n",
            "0    36864\n",
            "1    36864\n",
            "Name: count, dtype: int64\n",
            "J_P Balance:\n",
            " J_P\n",
            "1    44435\n",
            "0    44435\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import resample\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import kagglehub\n",
        "\n",
        "path = kagglehub.dataset_download(\"zeyadkhalid/mbti-personality-types-500-dataset\")\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "df = pd.read_csv(f\"{path}/MBTI 500.csv\")\n",
        "df = df.dropna(subset=['type', 'posts'])\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=1000, max_df=0.9)\n",
        "X = vectorizer.fit_transform(df['posts']).toarray()\n",
        "\n",
        "df['I_E'] = df['type'].apply(lambda x: 1 if x[0] == 'E' else 0)\n",
        "df['N_S'] = df['type'].apply(lambda x: 1 if x[1] == 'S' else 0)\n",
        "df['T_F'] = df['type'].apply(lambda x: 1 if x[2] == 'F' else 0)\n",
        "df['J_P'] = df['type'].apply(lambda x: 1 if x[3] == 'P' else 0)\n",
        "\n",
        "def downsample(df, target_col):\n",
        "    minority_class_size = df[target_col].value_counts().min()\n",
        "    df_majority = df[df[target_col] == df[target_col].value_counts().idxmax()]\n",
        "    df_minority = df[df[target_col] == df[target_col].value_counts().idxmin()]\n",
        "    df_majority_downsampled = resample(\n",
        "        df_majority,\n",
        "        replace=False,\n",
        "        n_samples=minority_class_size,\n",
        "        random_state=42\n",
        "    )\n",
        "    df_balanced = pd.concat([df_majority_downsampled, df_minority])\n",
        "    return df_balanced\n",
        "\n",
        "df_ie_balanced = downsample(df, 'I_E')\n",
        "df_ns_balanced = downsample(df, 'N_S')\n",
        "df_tf_balanced = downsample(df, 'T_F')\n",
        "df_jp_balanced = downsample(df, 'J_P')\n",
        "\n",
        "print(\"I_E Balance:\\n\", df_ie_balanced['I_E'].value_counts())\n",
        "print(\"N_S Balance:\\n\", df_ns_balanced['N_S'].value_counts())\n",
        "print(\"T_F Balance:\\n\", df_tf_balanced['T_F'].value_counts())\n",
        "print(\"J_P Balance:\\n\", df_jp_balanced['J_P'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_predict_rf(X_train, y_train, X_test, y_test, label):\n",
        "    model = RandomForestClassifier(\n",
        "    n_estimators=500,\n",
        "    max_depth=30,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=3,\n",
        "    max_features='sqrt',\n",
        "    class_weight='balanced',\n",
        "    random_state=42\n",
        "    )\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Accuracy for {label}: {accuracy}\")\n",
        "    return model\n",
        "\n",
        "def prepare_and_train_rf(df_balanced, label):\n",
        "    X_balanced = vectorizer.transform(df_balanced['posts']).toarray()\n",
        "    y_balanced = df_balanced[label]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42)\n",
        "    model = train_and_predict_rf(X_train, y_train, X_test, y_test, label)\n",
        "    return model, X_test, y_test\n",
        "\n",
        "model_ie, X_test_ie, y_test_ie = prepare_and_train_rf(df_ie_balanced, 'I_E')\n",
        "model_ns, X_test_ns, y_test_ns = prepare_and_train_rf(df_ns_balanced, 'N_S')\n",
        "model_tf, X_test_tf, y_test_tf = prepare_and_train_rf(df_tf_balanced, 'T_F')\n",
        "model_jp, X_test_jp, y_test_jp = prepare_and_train_rf(df_jp_balanced, 'J_P')\n",
        "\n",
        "def calculate_final_accuracy_rf(X_test, y_test_full):\n",
        "    predictions = []\n",
        "    for x in X_test:\n",
        "        x = x.reshape(1, -1)\n",
        "        ie = 'E' if model_ie.predict(x)[0] == 1 else 'I'\n",
        "        ns = 'S' if model_ns.predict(x)[0] == 1 else 'N'\n",
        "        tf = 'F' if model_tf.predict(x)[0] == 1 else 'T'\n",
        "        jp = 'P' if model_jp.predict(x)[0] == 1 else 'J'\n",
        "\n",
        "    correct_predictions = sum([1 for true, pred in zip(y_test_full, predictions) if true == pred])\n",
        "    final_accuracy = correct_predictions / len(y_test_full)\n",
        "    return final_accuracy\n",
        "\n",
        "X_full_test, y_full_test = vectorizer.transform(df['posts']).toarray(), df['type']\n",
        "final_accuracy_rf = calculate_final_accuracy_rf(X_full_test, y_full_test)\n",
        "print(\"Final MBTI Prediction Accuracy (Random Forest):\", final_accuracy_rf)\n",
        "\n",
        "def predict_mbti_rf(text):\n",
        "    x = vectorizer.transform([text]).toarray()\n",
        "    ie = 'E' if model_ie.predict(x)[0] == 1 else 'I'\n",
        "    ns = 'S' if model_ns.predict(x)[0] == 1 else 'N'\n",
        "    tf = 'F' if model_tf.predict(x)[0] == 1 else 'T'\n",
        "    jp = 'P' if model_jp.predict(x)[0] == 1 else 'J'\n",
        "    return ie + ns + tf + jp\n",
        "\n",
        "sample_text = \"I enjoy deep conversations and reflecting on philosophical topics.\"\n",
        "predicted_mbti_rf = predict_mbti_rf(sample_text)\n",
        "print(\"Predicted MBTI (Random Forest):\", predicted_mbti_rf)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SWbe9S060gf",
        "outputId": "ec04d451-9bf6-43cd-c344-4097cedd90b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for I_E: 0.8382237101220953\n",
            "Accuracy for N_S: 0.8660690029883183\n",
            "Accuracy for T_F: 0.8873592838735929\n",
            "Accuracy for J_P: 0.8451670980083268\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, title):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"0\", \"1\"], yticklabels=[\"0\", \"1\"])\n",
        "    plt.title(f\"Confusion Matrix: {title}\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.show()\n",
        "\n",
        "def calculate_and_plot_confusion(models, X_tests, y_tests, labels):\n",
        "    for model, X_test, y_test, label in zip(models, X_tests, y_tests, labels):\n",
        "        y_pred = model.predict(X_test)\n",
        "        plot_confusion_matrix(y_test, y_pred, title=label)\n",
        "\n",
        "models = [model_ie, model_ns, model_tf, model_jp]\n",
        "X_tests = [X_test_ie, X_test_ns, X_test_tf, X_test_jp]\n",
        "y_tests = [y_test_ie, y_test_ns, y_test_tf, y_test_jp]\n",
        "labels = [\"I/E\", \"N/S\", \"T/F\", \"J/P\"]\n",
        "\n",
        "calculate_and_plot_confusion(models, X_tests, y_tests, labels)\n"
      ],
      "metadata": {
        "id": "MpwUk98g7LxF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "af5ef02b-12ef-4e94-a745-74d6320a4f9d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model_ie' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-685e09e1e9f4>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# 모델과 데이터 리스트 준비\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel_ie\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_ns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_tf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_jp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mX_tests\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mX_test_ie\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_ns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_tf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_jp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0my_tests\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my_test_ie\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_ns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_tf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_jp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model_ie' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hxWy0cqBv7tq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}