{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDfChIlTjt6t",
        "outputId": "ecffd862-1b54-4385-b49e-23be1e23ca48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/zeyadkhalid/mbti-personality-types-500-dataset/versions/1\n",
            "I_E Balance:\n",
            " I_E\n",
            "0    25390\n",
            "1    25390\n",
            "Name: count, dtype: int64\n",
            "N_S Balance:\n",
            " N_S\n",
            "0    9201\n",
            "1    9201\n",
            "Name: count, dtype: int64\n",
            "T_F Balance:\n",
            " T_F\n",
            "0    36864\n",
            "1    36864\n",
            "Name: count, dtype: int64\n",
            "J_P Balance:\n",
            " J_P\n",
            "1    44435\n",
            "0    44435\n",
            "Name: count, dtype: int64\n",
            "Accuracy for I_E: 0.8610673493501378\n",
            "Accuracy for N_S: 0.8845422439554469\n",
            "Accuracy for T_F: 0.9002441340024413\n",
            "Accuracy for J_P: 0.8609767075503545\n",
            "Final MBTI Prediction Accuracy with tuned parameters: 0.7527411918881461\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import resample\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import kagglehub\n",
        "\n",
        "# Kaggle 데이터 다운로드\n",
        "path = kagglehub.dataset_download(\"zeyadkhalid/mbti-personality-types-500-dataset\")\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "# 데이터 로드 및 전처리\n",
        "df = pd.read_csv(f\"{path}/MBTI 500.csv\")\n",
        "df = df.dropna(subset=['type', 'posts'])\n",
        "\n",
        "\n",
        "# TF-IDF 변환\n",
        "vectorizer = TfidfVectorizer(max_features=1000, max_df=0.9)\n",
        "X = vectorizer.fit_transform(df['posts']).toarray()\n",
        "\n",
        "# 각 차원별 레이블 생성\n",
        "df['I_E'] = df['type'].apply(lambda x: 1 if x[0] == 'E' else 0)\n",
        "df['N_S'] = df['type'].apply(lambda x: 1 if x[1] == 'S' else 0)\n",
        "df['T_F'] = df['type'].apply(lambda x: 1 if x[2] == 'F' else 0)\n",
        "df['J_P'] = df['type'].apply(lambda x: 1 if x[3] == 'P' else 0)\n",
        "\n",
        "# DownSampling 함수 정의\n",
        "def downsample(df, target_col):\n",
        "    minority_class_size = df[target_col].value_counts().min()\n",
        "    df_majority = df[df[target_col] == df[target_col].value_counts().idxmax()]\n",
        "    df_minority = df[df[target_col] == df[target_col].value_counts().idxmin()]\n",
        "    df_majority_downsampled = resample(\n",
        "        df_majority,\n",
        "        replace=False,\n",
        "        n_samples=minority_class_size,\n",
        "        random_state=42\n",
        "    )\n",
        "    df_balanced = pd.concat([df_majority_downsampled, df_minority])\n",
        "    return df_balanced\n",
        "\n",
        "# 각 차원별 DownSampling 수행\n",
        "df_ie_balanced = downsample(df, 'I_E')\n",
        "df_ns_balanced = downsample(df, 'N_S')\n",
        "df_tf_balanced = downsample(df, 'T_F')\n",
        "df_jp_balanced = downsample(df, 'J_P')\n",
        "\n",
        "# DownSampling 후 데이터 확인\n",
        "print(\"I_E Balance:\\n\", df_ie_balanced['I_E'].value_counts())\n",
        "print(\"N_S Balance:\\n\", df_ns_balanced['N_S'].value_counts())\n",
        "print(\"T_F Balance:\\n\", df_tf_balanced['T_F'].value_counts())\n",
        "print(\"J_P Balance:\\n\", df_jp_balanced['J_P'].value_counts())\n",
        "\n",
        "# 학습 및 평가 함수 정의 (파라미터 수정 포함)\n",
        "def train_and_predict(X_train, y_train, X_test, y_test, label):\n",
        "    # GradientBoostingClassifier 모델 정의 및 파라미터 설정\n",
        "    model = GradientBoostingClassifier(\n",
        "        n_estimators=200,      # 부스팅 단계 수\n",
        "        learning_rate=0.25,    # 학습률\n",
        "        max_depth=7,           # 트리 최대 깊이\n",
        "        subsample=0.9,         # 데이터 샘플링 비율\n",
        "        min_samples_split=5,   # 노드 분할에 필요한 최소 샘플 수\n",
        "        min_samples_leaf=2,    # 리프 노드에 필요한 최소 샘플 수\n",
        "        random_state=42        # 랜덤 시드 설정\n",
        "    )\n",
        "\n",
        "    # 모델 학습\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # 예측 및 평가\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Accuracy for {label}: {accuracy}\")\n",
        "    return model\n",
        "\n",
        "# 각 차원별 데이터 분할 및 모델 학습\n",
        "def prepare_and_train(df_balanced, label):\n",
        "    X_balanced = vectorizer.transform(df_balanced['posts']).toarray()\n",
        "    y_balanced = df_balanced[label]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42)\n",
        "    model = train_and_predict(X_train, y_train, X_test, y_test, label)\n",
        "    return model, X_test, y_test\n",
        "\n",
        "# 각 차원별 학습\n",
        "model_ie, X_test_ie, y_test_ie = prepare_and_train(df_ie_balanced, 'I_E')\n",
        "model_ns, X_test_ns, y_test_ns = prepare_and_train(df_ns_balanced, 'N_S')\n",
        "model_tf, X_test_tf, y_test_tf = prepare_and_train(df_tf_balanced, 'T_F')\n",
        "model_jp, X_test_jp, y_test_jp = prepare_and_train(df_jp_balanced, 'J_P')\n",
        "\n",
        "# 최종 MBTI 예측 및 정확도 계산\n",
        "def calculate_final_accuracy(X_test, y_test_full):\n",
        "    predictions = []\n",
        "    for x in X_test:\n",
        "        x = x.reshape(1, -1)\n",
        "        ie = 'E' if model_ie.predict(x)[0] == 1 else 'I'\n",
        "        ns = 'S' if model_ns.predict(x)[0] == 1 else 'N'\n",
        "        tf = 'F' if model_tf.predict(x)[0] == 1 else 'T'\n",
        "        jp = 'P' if model_jp.predict(x)[0] == 1 else 'J'\n",
        "        predictions.append(ie + ns + tf + jp)\n",
        "\n",
        "    correct_predictions = sum([1 for true, pred in zip(y_test_full, predictions) if true == pred])\n",
        "    final_accuracy = correct_predictions / len(y_test_full)\n",
        "    return final_accuracy\n",
        "\n",
        "# 전체 MBTI 유형 데이터로 최종 예측\n",
        "X_full_test, y_full_test = vectorizer.transform(df['posts']).toarray(), df['type']\n",
        "final_accuracy = calculate_final_accuracy(X_full_test, y_full_test)\n",
        "print(\"Final MBTI Prediction Accuracy with tuned parameters:\", final_accuracy)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}