{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNHkujebI94N",
        "outputId": "478751a0-7e1d-4386-8f40-9786dd70fbde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/zeyadkhalid/mbti-personality-types-500-dataset/versions/1\n",
            "Grid search for I/E dimension:\n",
            "Max Depth: 2, Accuracy: 0.8670\n",
            "Max Depth: 3, Accuracy: 0.8790\n",
            "Max Depth: 5, Accuracy: 0.8847\n",
            "Max Depth: 7, Accuracy: 0.8889\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# Kaggle 데이터 다운로드 (kagglehub 라이브러리 필요)\n",
        "import kagglehub\n",
        "path = kagglehub.dataset_download(\"zeyadkhalid/mbti-personality-types-500-dataset\")\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "# 데이터 로드 및 전처리\n",
        "df = pd.read_csv(f\"{path}/MBTI 500.csv\")\n",
        "df = df.dropna(subset=['type', 'posts'])\n",
        "\n",
        "# TF-IDF 변환\n",
        "vectorizer = TfidfVectorizer(max_features=1000, max_df=0.9)\n",
        "X_full = vectorizer.fit_transform(df['posts']).toarray()\n",
        "\n",
        "# 각 차원별 레이블 생성\n",
        "df['I_E'] = df['type'].apply(lambda x: 1 if x[0] == 'E' else 0)\n",
        "df['N_S'] = df['type'].apply(lambda x: 1 if x[1] == 'S' else 0)\n",
        "df['T_F'] = df['type'].apply(lambda x: 1 if x[2] == 'F' else 0)\n",
        "df['J_P'] = df['type'].apply(lambda x: 1 if x[3] == 'P' else 0)\n",
        "\n",
        "# 그리드 서치 함수 정의\n",
        "def grid_search_for_dimension(X, y, label, max_depth_values):\n",
        "    accuracies = []\n",
        "    print(f\"Grid search for {label} dimension:\")\n",
        "\n",
        "    for max_depth in max_depth_values:\n",
        "        # 모델 초기화\n",
        "        model = GradientBoostingClassifier(\n",
        "            n_estimators=200,      # 부스팅 단계 수\n",
        "            learning_rate=0.1,     # 학습률\n",
        "            max_depth=max_depth,   # 트리 깊이\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "        # 데이터 분할\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        # 모델 학습\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # 예측 및 정확도 평가\n",
        "        y_pred = model.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        accuracies.append((max_depth, accuracy))\n",
        "        print(f\"Max Depth: {max_depth}, Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    # 최적 하이퍼파라미터 도출\n",
        "    best_max_depth, best_accuracy = max(accuracies, key=lambda x: x[1])\n",
        "    print(f\"Best Max Depth for {label}: {best_max_depth}, Best Accuracy: {best_accuracy:.4f}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    return best_max_depth, best_accuracy\n",
        "\n",
        "# 차원별로 그리드 서치 및 모델 학습\n",
        "max_depth_values = [2,3,5,7,9]\n",
        "best_models = {}\n",
        "\n",
        "for dimension, label in zip(['I/E', 'N/S', 'T/F', 'J/P'], ['I_E', 'N_S', 'T_F', 'J_P']):\n",
        "    y_dimension = df[label]\n",
        "    best_max_depth, best_accuracy = grid_search_for_dimension(X_full, y_dimension, dimension, max_depth_values)\n",
        "    best_models[dimension] = {'max_depth': best_max_depth, 'accuracy': best_accuracy}\n",
        "\n",
        "# 최종 Total 정확도 계산 함수\n",
        "def calculate_total_accuracy(X, df, best_models):\n",
        "    X_train, X_test, df_train, df_test = train_test_split(X, df, test_size=0.2, random_state=42)\n",
        "    correct_predictions = 0\n",
        "\n",
        "    for idx, x in enumerate(X_test):\n",
        "        x = x.reshape(1, -1)\n",
        "\n",
        "        # 각 차원의 예측 수행\n",
        "        predictions = []\n",
        "        for dimension, model_info in best_models.items():\n",
        "            label = dimension.replace(\"/\", \"_\")  # 예: I/E -> I_E\n",
        "            model = GradientBoostingClassifier(\n",
        "                n_estimators=200,\n",
        "                learning_rate=0.1,\n",
        "                max_depth=model_info['max_depth'],\n",
        "                random_state=42\n",
        "            )\n",
        "            model.fit(X_train, df_train[label])\n",
        "            pred = model.predict(x)[0]\n",
        "            predictions.append(pred)\n",
        "\n",
        "        # MBTI 유형 변환\n",
        "        ie = 'E' if predictions[0] == 1 else 'I'\n",
        "        ns = 'S' if predictions[1] == 1 else 'N'\n",
        "        tf = 'F' if predictions[2] == 1 else 'T'\n",
        "        jp = 'P' if predictions[3] == 1 else 'J'\n",
        "        predicted_type = ie + ns + tf + jp\n",
        "\n",
        "        # 실제 MBTI 유형과 비교\n",
        "        if predicted_type == df_test.iloc[idx]['type']:\n",
        "            correct_predictions += 1\n",
        "\n",
        "    total_accuracy = correct_predictions / len(X_test)\n",
        "    return total_accuracy\n",
        "\n",
        "# 최종 Total 정확도 출력\n",
        "total_accuracy = calculate_total_accuracy(X_full, df, best_models)\n",
        "print(f\"Total MBTI Prediction Accuracy: {total_accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import resample\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import kagglehub\n",
        "\n",
        "# Kaggle 데이터 다운로드\n",
        "path = kagglehub.dataset_download(\"zeyadkhalid/mbti-personality-types-500-dataset\")\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "# 데이터 로드 및 전처리\n",
        "df = pd.read_csv(f\"{path}/MBTI 500.csv\")\n",
        "df = df.dropna(subset=['type', 'posts'])\n",
        "\n",
        "\n",
        "# TF-IDF 변환\n",
        "vectorizer = TfidfVectorizer(max_features=1000, max_df=0.9)\n",
        "X = vectorizer.fit_transform(df['posts']).toarray()\n",
        "\n",
        "# 각 차원별 레이블 생성\n",
        "df['I_E'] = df['type'].apply(lambda x: 1 if x[0] == 'E' else 0)\n",
        "df['N_S'] = df['type'].apply(lambda x: 1 if x[1] == 'S' else 0)\n",
        "df['T_F'] = df['type'].apply(lambda x: 1 if x[2] == 'F' else 0)\n",
        "df['J_P'] = df['type'].apply(lambda x: 1 if x[3] == 'P' else 0)\n",
        "\n",
        "# DownSampling 함수 정의\n",
        "def downsample(df, target_col):\n",
        "    minority_class_size = df[target_col].value_counts().min()\n",
        "    df_majority = df[df[target_col] == df[target_col].value_counts().idxmax()]\n",
        "    df_minority = df[df[target_col] == df[target_col].value_counts().idxmin()]\n",
        "    df_majority_downsampled = resample(\n",
        "        df_majority,\n",
        "        replace=False,\n",
        "        n_samples=minority_class_size,\n",
        "        random_state=42\n",
        "    )\n",
        "    df_balanced = pd.concat([df_majority_downsampled, df_minority])\n",
        "    return df_balanced\n",
        "\n",
        "# 각 차원별 DownSampling 수행\n",
        "df_ie_balanced = downsample(df, 'I_E')\n",
        "df_ns_balanced = downsample(df, 'N_S')\n",
        "df_tf_balanced = downsample(df, 'T_F')\n",
        "df_jp_balanced = downsample(df, 'J_P')\n",
        "\n",
        "# DownSampling 후 데이터 확인\n",
        "print(\"I_E Balance:\\n\", df_ie_balanced['I_E'].value_counts())\n",
        "print(\"N_S Balance:\\n\", df_ns_balanced['N_S'].value_counts())\n",
        "print(\"T_F Balance:\\n\", df_tf_balanced['T_F'].value_counts())\n",
        "print(\"J_P Balance:\\n\", df_jp_balanced['J_P'].value_counts())\n",
        "\n",
        "# 학습 및 평가 함수 정의 (파라미터 수정 포함)\n",
        "def train_and_predict(X_train, y_train, X_test, y_test, label):\n",
        "    # GradientBoostingClassifier 모델 정의 및 파라미터 설정\n",
        "    model = GradientBoostingClassifier(\n",
        "        n_estimators=200,      # 부스팅 단계 수\n",
        "        learning_rate=0.05,    # 학습률\n",
        "        max_depth=2,           # 트리 최대 깊이\n",
        "        subsample=0.9,         # 데이터 샘플링 비율\n",
        "        min_samples_split=5,   # 노드 분할에 필요한 최소 샘플 수\n",
        "        min_samples_leaf=2,    # 리프 노드에 필요한 최소 샘플 수\n",
        "        random_state=42        # 랜덤 시드 설정\n",
        "    )\n",
        "\n",
        "    # 모델 학습\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # 예측 및 평가\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Accuracy for {label}: {accuracy}\")\n",
        "    return model\n",
        "\n",
        "# 각 차원별 데이터 분할 및 모델 학습\n",
        "def prepare_and_train(df_balanced, label):\n",
        "    X_balanced = vectorizer.transform(df_balanced['posts']).toarray()\n",
        "    y_balanced = df_balanced[label]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42)\n",
        "    model = train_and_predict(X_train, y_train, X_test, y_test, label)\n",
        "    return model, X_test, y_test\n",
        "\n",
        "# 각 차원별 학습\n",
        "model_ie, X_test_ie, y_test_ie = prepare_and_train(df_ie_balanced, 'I_E')\n",
        "model_ns, X_test_ns, y_test_ns = prepare_and_train(df_ns_balanced, 'N_S')\n",
        "model_tf, X_test_tf, y_test_tf = prepare_and_train(df_tf_balanced, 'T_F')\n",
        "model_jp, X_test_jp, y_test_jp = prepare_and_train(df_jp_balanced, 'J_P')\n",
        "\n",
        "# 최종 MBTI 예측 및 정확도 계산\n",
        "def calculate_final_accuracy(X_test, y_test_full):\n",
        "    predictions = []\n",
        "    for x in X_test:\n",
        "        x = x.reshape(1, -1)\n",
        "        ie = 'E' if model_ie.predict(x)[0] == 1 else 'I'\n",
        "        ns = 'S' if model_ns.predict(x)[0] == 1 else 'N'\n",
        "        tf = 'F' if model_tf.predict(x)[0] == 1 else 'T'\n",
        "        jp = 'P' if model_jp.predict(x)[0] == 1 else 'J'\n",
        "        predictions.append(ie + ns + tf + jp)\n",
        "\n",
        "    correct_predictions = sum([1 for true, pred in zip(y_test_full, predictions) if true == pred])\n",
        "    final_accuracy = correct_predictions / len(y_test_full)\n",
        "    return final_accuracy\n",
        "\n",
        "# 전체 MBTI 유형 데이터로 최종 예측\n",
        "X_full_test, y_full_test = vectorizer.transform(df['posts']).toarray(), df['type']\n",
        "final_accuracy = calculate_final_accuracy(X_full_test, y_full_test)\n",
        "print(\"Final MBTI Prediction Accuracy with tuned parameters:\", final_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OPcToMqI91E",
        "outputId": "fc8becd0-896c-42d2-c32b-237a4a4277c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/zeyadkhalid/mbti-personality-types-500-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 123M/123M [00:03<00:00, 36.1MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/zeyadkhalid/mbti-personality-types-500-dataset/versions/1\n",
            "I_E Balance:\n",
            " I_E\n",
            "0    25390\n",
            "1    25390\n",
            "Name: count, dtype: int64\n",
            "N_S Balance:\n",
            " N_S\n",
            "0    9201\n",
            "1    9201\n",
            "Name: count, dtype: int64\n",
            "T_F Balance:\n",
            " T_F\n",
            "0    36864\n",
            "1    36864\n",
            "Name: count, dtype: int64\n",
            "J_P Balance:\n",
            " J_P\n",
            "1    44435\n",
            "0    44435\n",
            "Name: count, dtype: int64\n",
            "Accuracy for I_E: 0.8171524222134698\n",
            "Accuracy for N_S: 0.8489540885628906\n",
            "Accuracy for T_F: 0.8567747185677472\n",
            "Accuracy for J_P: 0.8255316754810397\n",
            "Final MBTI Prediction Accuracy with tuned parameters: 0.5740428219898743\n"
          ]
        }
      ]
    }
  ]
}